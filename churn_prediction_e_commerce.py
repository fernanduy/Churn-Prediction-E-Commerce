# -*- coding: utf-8 -*-
"""Churn Prediction E-Commerce.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1CCWeMrjpUMKPm7CiRKaS2SIIPcOi7AhL

# IMPORT LIBRARY
"""

import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt

"""# LOADING DATASET"""

#MEMBACA DATASET
data = pd.read_excel('finalproject.xlsx', sheet_name=1)
data.head(20)

"""# DATA QUALITY CHECKING"""

#Mengetahui jumlah baris dan kolom
data.shape

#Mengetahui informasi dataset
data.info()

"""1. data terlihat ada beberapa missing value dan harus diatasi (tidak bisa dihapus karena data missing total diatas 10% dari jumlah data)

2. ada data yang terlihat invalid values yaitu WarehouseToHome, HourSpendOnApp, OrderAmountHikeFromlastYear, CouponUsed, OrderCount, DaySinceLastOrder karena seharusnya data bertipe integer.

3. variable data ini masih mengandung 2 tipe data yaitu string dan numerikal, untuk dari itu perlu dibagi menjadi 2 agar dapat dilakukan statistika deskriptif sehingga dapat melihat karakteristik data itu sendiri.
"""

#Mengecek total missing value
data.isnull().sum()

#Mengecek total data duplikat
data.duplicated().sum()

"""# EXPLORATORY DATA ANALYSIS"""

#Mengelompokan data numerik dan categorical
num = ['Churn', 'Tenure', 'CityTier', 'WarehouseToHome', 'HourSpendOnApp', 'NumberOfDeviceRegistered', 'SatisfactionScore', 'NumberOfAddress',
       'Complain', 'OrderAmountHikeFromlastYear', 'CouponUsed', 'OrderCount', 'DaySinceLastOrder', 'CashbackAmount']
cat = ['PreferredLoginDevice', 'PreferredPaymentMode', 'Gender', 'PreferedOrderCat', 'MaritalStatus']

#Mengetahui statistik tipe data numerik
data[num].describe()

"""
1. Rata - rata masa kerjasama pelanggan dengan perusahaan adalah 10 bulan
2. Rata - rata jarak rumah pelanggan ke gudang 10 meter
3. Skor kepuasan pelanggan terhadap layanan rerata ada dinilai 3 dari nilai tertinggi yaitu 5
4. Rerata jumlah pesanan tiap user adalah 3 item


"""

#Mengetahui statistik tipe data categorical
data[cat].describe()

"""1. Para pelanggan paling banyak berasal dari gender laki-laki
2. Para pelanggan paling banyak membeli produk Laptop dan Aksesoris
3. Pelanggan sebagian besar sudah berkeluarga
4. Para pelanggan lebih banyak menggunakan perangkat mobile phone untuk login device penggunanya
5. Pelanggan lebih banyak menggunakan media pembayaran debit card
"""

for col in cat:
    print(f'''Value count kolom {col}:''')
    print(data[col].value_counts())
    print()

for col in num:
    print(f'''Value count kolom {col}:''')
    print(data[col].value_counts())
    print()

"""# Univariate Analysist"""

data_missing = ['Tenure', 'WarehouseToHome', 'HourSpendOnApp', 'OrderAmountHikeFromlastYear', 'CouponUsed', 'OrderCount', 'DaySinceLastOrder']

#Individual Box Plot
feature = data_missing
plt.figure(figsize=(25,10))
for i in range(0, len(feature)):
    plt.subplot(2, 4, i+1)
    sns.boxplot(data[feature[i]], color='red')
    plt.tight_layout()

#Individual Distplot
plt.figure(figsize=(25,20))
for i in range(0, len(feature)):
    plt.subplot(2, 4, i+1)
    sns.distplot(data[feature[i]], color='green')
    plt.tight_layout()

"""1. Untuk 'Tenure', 'WarehouseToHome', 'OrderAmountHikeFromlastYear', 'CouponUsed', 'OrderCount', 'DaySinceLastOrder' terdapat skiew. Oleh karena itu, handle missing value nya menggunakan nilai mean
2. Untuk 'HourSpendOnApp' merupakan distribusi normal, dan handle missing value nya menggunakan nilai modus
"""

#Correlation Heatmap
plt.figure(figsize=(15,15))
sns.heatmap(data.corr(), cmap = 'Blues', annot=True, fmt='.2')

#Pair Plot
plt.figure(figsize=(15,15))
sns.pairplot(data, diag_kind = 'kde')

"""1. Semakin meningkat jumlah kupon yang digunakan bulan lalu, maka semakin meningkat pula jumlah orderan pada bulan lalu"""

#Handle Missing Value
data['Tenure'].fillna(data['Tenure'].median(), inplace=True)
data['WarehouseToHome'].fillna(data['WarehouseToHome'].median(), inplace=True)
data['HourSpendOnApp'].fillna(data['HourSpendOnApp'].mean(), inplace=True)
data['OrderAmountHikeFromlastYear'].fillna(data['OrderAmountHikeFromlastYear'].median(), inplace=True)
data['CouponUsed'].fillna(data['CouponUsed'].median(), inplace=True)
data['OrderCount'].fillna(data['OrderCount'].median(), inplace=True)
data['DaySinceLastOrder'].fillna(data['DaySinceLastOrder'].median(), inplace=True)
data.isnull().sum()

data.shape

data.info()

#merubah tipe data
#float to int
data['Tenure'] = data['Tenure'].astype('int')
data['WarehouseToHome'] = data['WarehouseToHome'].astype('int')
data['HourSpendOnApp'] = data['HourSpendOnApp'].astype('int')
data['OrderAmountHikeFromlastYear'] = data['OrderAmountHikeFromlastYear'].astype('int')
data['CouponUsed'] = data['CouponUsed'].astype('int')
data['OrderCount'] = data['OrderCount'].astype('int')
data['DaySinceLastOrder'] = data['DaySinceLastOrder'].astype('int')
data['CashbackAmount'] = data['CashbackAmount'].astype('int')

data.info()

"""# MODELLING"""

from sklearn.model_selection import train_test_split

x = data.drop(['Churn', 'CustomerID'], axis=1)
y = data['Churn']

xtrain, xtest, ytrain, ytest = train_test_split(x, y, test_size=0.25, stratify=y, random_state=75)

from sklearn.pipeline import Pipeline
from sklearn.preprocessing import MinMaxScaler, OneHotEncoder

numerical_pipeline = Pipeline([('scaler', MinMaxScaler())])

categorical_pipeline = Pipeline([('onehot', OneHotEncoder())])

from sklearn.compose import ColumnTransformer

preprcessor = ColumnTransformer([('numeric', numerical_pipeline, 
                                  ['Tenure', 'WarehouseToHome', 'HourSpendOnApp', 'NumberOfDeviceRegistered', 'NumberOfAddress', 'OrderAmountHikeFromlastYear', 'CouponUsed', 'OrderCount', 'DaySinceLastOrder', 'CashbackAmount']),
                                 ('categoric', categorical_pipeline, 
                                  ['CityTier', 'SatisfactionScore', 'Complain', 'MaritalStatus', 'PreferedOrderCat', 'Gender', 'PreferredPaymentMode', 'PreferredLoginDevice'])])

"""#Logistic Regression"""

from sklearn.linear_model import LogisticRegression

pipeline_lr = Pipeline([('prep', preprcessor), ('algo', LogisticRegression())])

pipeline_lr.fit(xtrain, ytrain)

y_predict = pipeline_lr.predict(xtest)

#metode evaluasi
from sklearn.metrics import classification_report, confusion_matrix
print('\nconfustion matrix')                                                    #generate the confusion matrix
print(confusion_matrix(ytest, y_predict))

from sklearn.metrics import accuracy_score
print('\naccuracy')
print(accuracy_score(ytest, y_predict))

from sklearn.metrics import classification_report
print('\nclassification report')
print(classification_report(ytest, y_predict))

pipeline_lr.score(xtrain, ytrain), pipeline_lr.score(xtest, ytest)

"""Karena menggunakan model Logistic Regression nilai akurasinya kurang yaitu 0,8. Maka untuk perbaikan digunakan model Random Forest Classifier

#Random Forest Classifier
"""

from sklearn.ensemble import RandomForestClassifier

pipeline_rf = Pipeline([('prep', preprcessor), ('algo', RandomForestClassifier())])

pipeline_rf.fit(xtrain, ytrain)

y_predict = pipeline_rf.predict(xtest)

#metode evaluasi
from sklearn.metrics import classification_report, confusion_matrix
print('\nconfustion matrix')                                                    #generate the confusion matrix
print(confusion_matrix(ytest, y_predict))

from sklearn.metrics import accuracy_score
print('\naccuracy')
print(accuracy_score(ytest, y_predict))

from sklearn.metrics import classification_report
print('\nclassification report')
print(classification_report(ytest, y_predict))

"""Saat digunakan model Random Forest Classifier didapatkan nilai akurasi yang cukup bagus yaitu 0,95. Jadi dapat disimpulkan untuk model yang dipilih adalah model "Random Forest Classifier"

***EXECUTIVE SUMMARY & RECOMMENDATION***

1. Pelanggan yang berpotensi churn adalah pelanggan yang sudah lama bergabung bersama perusahaan, sehingga dapat dibuat kebijakan penambahan benefit bertingkat sesuai dengan masa bergabung customer.
2. Komplain dari customer merupakan masukan yang sangat berharga bagi perusahaan, jika customer melakukan komplain berarti customer peduli pada perkembangan perusahaan. Perusahaan harus memberikan pelayanan komplain sebaik mungkin dan memberikan reward untuk setiap masukan dari customer.
3. Customer yang sudah menikah lebih cenderung churn, hal ini kemungkinan disebabkan karena orang yang sudah menikah cenderung tidak memiliki waktu untuk mengecek kompetitor dan memiliki list belanjaan yang sudah pasti. Untuk itu perlu dibuat periode diskon khsus untuk kebutuhan rumah tangga.
"""